{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446bceb7",
   "metadata": {},
   "source": [
    "Similar to GAN_dogs but trained on the local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5085a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aac9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "image_size = (28,28,1)\n",
    "latent_dim = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7675c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 64)        640       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 128)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,625\n",
      "Trainable params: 74,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Fixing discriminator\n",
    "discriminator = Sequential()\n",
    "discriminator.add(layers.Conv2D(64, 3, strides = 2, padding = 'same', input_shape = image_size))\n",
    "discriminator.add(layers.LeakyReLU(alpha=0.2))\n",
    "discriminator.add(layers.Conv2D(128,3,strides=2,padding='same'))\n",
    "discriminator.add(layers.LeakyReLU(alpha=0.2))\n",
    "discriminator.add(layers.GlobalMaxPooling2D())\n",
    "discriminator.add(layers.Dense(1))\n",
    "\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "207a8c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 6272)              627200    \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 6272)              0         \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2D  (None, 14, 14, 128)      262272    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  (None, 28, 28, 128)      262272    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 1)         6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,158,017\n",
      "Trainable params: 1,158,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "generator.add(layers.Dense(7*7*128, use_bias=False, input_shape = (latent_dim,)))\n",
    "generator.add(layers.LeakyReLU(0.2))\n",
    "generator.add(layers.Reshape((7, 7, 128)))\n",
    "generator.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "generator.add(layers.LeakyReLU(0.2))\n",
    "generator.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "generator.add(layers.LeakyReLU(0.2))\n",
    "generator.add(layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid'))\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d99b5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN,self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "    \n",
    "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
    "        super(GAN,self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    \n",
    "    def train_step(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        noise_sample = tf.random.normal([batch_size, self.latent_dim])\n",
    "        \n",
    "        generated_images = self.generator(noise_sample)\n",
    "        \n",
    "        combined_images = tf.concat([generated_images, data], axis=0)\n",
    "        labels = tf.concat([tf.ones((batch_size,1)), tf.zeros((batch_size,1))], axis=0)\n",
    "        #labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads,self.discriminator.trainable_weights))\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        \n",
    "        noise_sample = tf.random.normal([batch_size, self.latent_dim])\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(noise_sample))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2aeb2466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-21 14:15:37.625844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  74/1094 [=>............................] - ETA: 2:36 - d_loss: 0.5613 - g_loss: 0.7834"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     13\u001b[0m     d_optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m),\n\u001b[1;32m     14\u001b[0m     g_optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m),\n\u001b[1;32m     15\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# To limit the execution time, we only train on 100 batches. You can train on\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# the entire dataset. You will need about 20 epochs to get nice results.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Först tränar vi på MNIST\n",
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "batch_size = 64\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# To limit the execution time, we only train on 100 batches. You can train on\n",
    "# the entire dataset. You will need about 20 epochs to get nice results.\n",
    "history = gan.fit(dataset, epochs=30)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['d_loss'], color='blue', label='discriminator loss')\n",
    "plt.plot(history.history['g_loss'], color='orange', label='generator loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2785383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting some generated images\n",
    "noise_sample = tf.random.normal([9, latent_dim])\n",
    "generated_images = gan.generator(noise_sample)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    currim = 255*generated_images[i].numpy()\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    plt.imshow(currim, cmap=\"gray\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0273f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sedan testar vi att träna på enbart några enstaka hundraser som dessutom är lika varandra\n",
    "a = generated_images[8]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd30a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.807742e-23"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(a.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
